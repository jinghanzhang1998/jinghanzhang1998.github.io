---
title: "Dynamic and Adaptive Feature Generation with LLM"
collection: publications
category: conferences
permalink: /publication/2025-ijcai-dafg-llm
date: 2024-06-04
venue: "IJCAI 2025 (accepted)"
authors: "Xinhao Zhang, Jinghan Zhang, Banafsheh Rekabdar, Yuanchun Zhou, Pengfei Wang, Kunpeng Liu"
paperurl: "https://arxiv.org/abs/2406.03505"
excerpt: "We propose a dynamic and adaptive feature generation method utilizing Large Language Models (LLMs), improving interpretability, applicability, and strategic flexibility in automated feature engineering."
---

The representation of feature space is a crucial environment where data points get vectorized and embedded for upcoming modeling. Thus the efficacy of machine learning (ML) algorithms is closely related to the quality of feature engineering. As one of the most important techniques, feature generation transforms raw data into an optimized feature space conducive to model training and further refines the space. Despite the advancements in automated feature engineering and feature generation, current methodologies often suffer from three fundamental issues: lack of explainability, limited applicability, and inflexible strategy. These shortcomings frequently hinder and limit the deployment of ML models across varied scenarios. Our research introduces a novel approach adopting large language models (LLMs) and feature-generating prompts to address these challenges. We propose a dynamic and adaptive feature generation method that enhances the interpretability of the feature generation process. Our approach broadens the applicability across various data types and tasks and draws advantages over strategic flexibility. A broad range of experiments showcases that our approach is significantly superior to existing methods.

ðŸ“„ *Accepted by IJCAI 2025*  
ðŸ”— [Paper Link (arXiv:2406.03505)](https://arxiv.org/abs/2406.03505)
